---
title: "chr_genderation_comparison"
format: html
execute:
  dir: project
---

# Introduction

In this analysis, I aim to create **Chromatograms objects** from the 
preprocessed LC-MS data, primarily using the functionality provided by the
**Chromatograms package**. The main goal is to compare full and extracted data
across different labs to understand how LC and MS setups influence the results.  

The comparison will proceed in multiple steps:

1. **Full Data Analysis**:  

   - Evaluate basic metrics such as BPC, TIC, and median intensity across
   retention time (RT) bins.  
   - Compute basic similarity metrics to assess data consistency across labs.  
   
1. **Detected Signal Analysis**:  

   - Focus on signals detected by peak picking algorithms, excluding baseline
     noise.  
   - Recompute the same metrics and similarity measures as in the full data
     analysis.  
   - This step aims to highlight differences in sensitivity and peak detection
     efficiency across labs. We hope to get more clear information on setup 
     specificity.

2. **Annotated Signal Analysis**:   

   - Use lab-provided annotations to extract only "annotated" signals.  
   - Recompute the same metrics and similarity measures.  
   - Examine EICs of annotated peaks and calculate a variety of metrics for 
     inter-lab comparison.  
   - Save these results for later use in a separate peak similarity analysis
     workflow, which will require evaluating multiple aspects of the data.  

Currently, only harmonized method data is available, meaning the samples were
run using the same column and protocol. Therefore, most observed differences 
are expected to originate from variations in MS setups.  

For now, this analysis focuses solely on the **human endosome mixture**, but
the workflow is designed to be extendable. A separate R script,
`rt_analysis_function.R`, contains custom functions used in this workflow.  

**Temporary notes for development**:  
- Implement `chromQuality()` to compute metrics on EICs.  
- Implement `chromSimilarities()` to calculate similarity metrics within a
  Chromatograms object.


## Load libraries

```{r, include=TRUE, warning=FALSE, message=FALSE}
library(Chromatograms)
library(Spectra)
library(xcms)
library(MsIO)
library(MsExperiment)
library(vioplot)
library(dtw)
library(pracma) ## easy find peak function, SWITch to MsCoreUtils
source("rt_analysis_function.R")
```

```{r}
# cluster parallel setting
bpparam <- MulticoreParam(workers = parallel::detectCores() - 1)
```

# Full data analysis

Below I load the preprocessed data from each lab.

```{r}
if (!file.exists("object/sp_full.RData")) {
  sp_afekta <- load_data(lab = "afekta", study_group = "HE")
  sp_hmgu <- load_data(lab = "hmgu", study_group = "HE")
  sp_icl <- load_data(lab = "icl", study_group = "HE")
  sp_cembio <- load_data(lab = "cembio", study_group = "HE")

  sp_full <- c(sp_afekta, sp_hmgu, sp_icl, sp_cembio)
  save(sp_full, file = "object/sp_full.RData")
  rm(sp_afekta, sp_hmgu, sp_icl, sp_cembio)
} else {
  load("object/sp_full.RData")
}
```

If we summarise the number of MS1 spectra per lab: 

```{r}
table(sp_full$lab) 
```

Below we summarize the rtime range per lab (in seconds). 
They should be fairly similar for the harmonized method as we agreed on a 
range during preprocessing.

```{r}
lapply(split(rtime(sp_full), sp_full$lab), range)
```


Insert table with experimental info later below: 

[table]

## Basic metrics

after discussion, maybe removing the bpc and tic evaluation makes sense and
only keep the bpc/tic ratio. 

### Base Peak Chromatogram (BPC) area

```{r, eval=I(!file.exists("object/bpc_full.RData"))}
if(!file.exists("object/bpc_full.RData")) {
  bpc_full <- Chromatograms(sp_full, summarize.method = "max",
                       factorize.by= "dataOrigin", 
                       spectraVariables = c("mixture", "lab")) 
  
  bpc_full <- setBackend(bpc_full, ChromBackendMemory())
  save(file = "object/bpc_full.RData", bpc_full)
} else {
  load("object/bpc_full.RData")
}
```

Below we compute the BPC area per mixture per lab and summarize across 
mixtures by summing the intensity values.

```{r}
# - sum intensity for each mixture
sbpc <- vapply(intensity(bpc_full), sum, numeric(1))
vioplot(log2(sbpc) ~ bpc_full$lab, ylab = "BPC area", xlab = "Lab")
```

Note: this above is not normalized, we could by TIC but we already compute 
the ratio below and it is probably the best computation anyway. 

next compute CV per mixture across lab
- here normalize by standard deviation divided by mean.

we are hoping to get some information about the agreement of the BPC signal
across lab.

```{r,eval=TRUE}
cv_per_mix <- tapply(sbpc, bpc_full$mixture, function(x) sd(x) / mean(x))
```


### Total Ion Current (TIC) area

Compare BPC area vs TIC area per lab.
If TIC is similar but BPC differs → different dominant ions detected.

```{r, eval =I(!file.exists("object/tic_full.RData"))}
tic_full <- Chromatograms(sp_full, summarize.method = "sum",
                     factorize.by= "dataOrigin",
                     spectraVariables = c("mixture", "lab"))
tic_full <- setBackend(tic_full, ChromBackendMemory())

save(file = "object/tic_full.RData", tic_full)
```

```{r, eval=I(file.exists("object/tic_full.RData"))}
load("object/tic_full.RData")
```

```{r, eval =TRUE}
# - sum intensity for each mixture
stic <- vapply(intensity(tic_full), sum, numeric(1))
boxplot(log2(stic) ~ tic_full$lab, ylab = "TIC area (log2)", xlab = "Lab", 
        main = "Total ion signal across mixtures")
```

Note: again this is not normalised. 


### ratio BPC / TIC

The ratio of bpc singal by tic signal gives information about the complexity of the
data. if close to 1 -> one dominant ion. if smaller 
then we are more spread across ions.  This inference would be more interesting 
when looking at the cleaned up data though. 

It is also very interesting to see how consistent this ratio is across lab. 
It essentialy normalise the BPC signal ( i think) 

```{r, eval=TRUE}
ratio_bpc_tic <- sbpc / stic
ratio_bpc_tic

vioplot(ratio_bpc_tic ~ tic_full$lab, ylab = "BPC / TIC area", xlab = "Lab")
```

It seems that we  are quite low. But would be interesting to compare to the
one calculated from the detected data. 

## tic/bpc ratio along rt 

Gives us some kind of chromatographic fingerprint per lab. 
Instead of baseline shape, you’re summarizing where peaks are detected along 
the gradient.
[the plots below are very bad now that i have all labs together.]

```{r ratio-full, eval = TRUE}
ratio_all <- sapply(seq_along(tic_full), function(i) {
  rt <- rtime(tic_full[i])[[1]]
  int_tic <- log2(intensity(tic_full[i])[[1]] + 1)  # +1 to avoid log2(0)
  int_bpc <- log2(intensity(bpc_full[i])[[1]] + 1)
  
  # Bin retention time into 30 equal slices
  bins <- cut(rt, breaks = 30)
  
  # Compute median ratio BPC/TIC per bin
  tapply(seq_along(rt), bins, function(idx) {
    median(int_bpc[idx] / int_tic[idx], na.rm = TRUE)
  })
})

colnames(ratio_all) <- paste(tic_full$lab, tic_full$mixture, "pol:", tic_full$polarity, sep = "_")
# Plot ratio for each mixture across labs
# | fig.width: 12
# | fig.height: 4

mixtures <- unique(tic_full$mixture)
par(mfrow = c(1, 2))
for (mix in mixtures) {
  cols <- grep(mix, colnames(ratio_all))
  matplot(ratio_all[, cols], type = "b", pch = 1
    , xlab = "RT slices", ylab = "Median BPC/TIC ratio", main = paste("Mixture", mix))
 #  legend("topright", legend = colnames(ratio_all)[cols], col =
 # 1:length(cols), pch = 1) ## improve plotting. 
}
```

Notes: i htink johannes wanted me to Summarized across labs but i'm not sure
exactly. see with him


## Chromatogram  Similarity

For this we use dtw, this measures baseline + peak shape similarity.
[insert more info about dtw and why we chose it here]

### full data 

Note: this takes quite a while to run. This might get removed from final 
analysis. 

```{r dtw-tic-full, eval = TRUE}
full_int <- intensity(tic_full)

#check if shape based, use difference datapoint. 
sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(tic_full$lab, tic_full$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(tic_full$lab, tic_full$mixture, sep = "_"),
  labCol = paste(tic_full$lab, tic_full$mixture, sep = "_"), main = "DTW similarity of TIC")
```

```{r dtw-bpc-full, eval = TRUE}
full_int <- intensity(bpc_full)

#check if shape based, use difference datapoint. 
sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(tic_full$lab, tic_full$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(tic_full$lab, tic_full$mixture, sep = "_"),
  labCol = paste(tic_full$lab, tic_full$mixture, sep = "_"), main = "DTW similarity of TIC")
```


### ratio along retention time. 

Are all labs consistent across the whole gradient, or only in certain
RT regions?

```{r, eval= FALSE}
sim_matrix_med <- matrix(NA, ncol = ncol(ratio_all), nrow = ncol(ratio_all))
for (i in seq_len(ncol(ratio_all))) {
  for (j in seq_len(ncol(ratio_all))) {
    if (is.na(sim_matrix_med[i, j])) {
      dtw_res <- dtw(ratio_all[, i], ratio_all[, j], keep = FALSE)
      sim_matrix_med[i, j] <- dtw_res$normalizedDistance
      sim_matrix_med[j, i] <- sim_matrix_med[i, j]
    }
  }
}
## clustering
hc_med <- hclust(as.dist(sim_matrix_med))
plot(hc_med, labels = colnames(medians_all), 
     main = "DTW clustering of tic/bpc ratio binned")

heatmap(sim_matrix_med, labRow = colnames(medians_all),
  labCol = colnames(medians_all), 
  main = "DTW similarity of tic/bpc ratio binned")
```

```{r}
## delete the memory hungry object 
rm(tic_full, bpc_full, sp_full)
```

# Detected signal analysis

This signal is essentially keeping the rt and mz area from peak detection. 
Now it reflects total detected signal (sensitivity of detection).

Easier to compare labs because baseline noise is excluded.
Differences now relate more to how well peaks were detected and instrument 
sensitivity rather than background noise. 

Load the results sheet below 

```{r}
if (!file.exists("object/sp_full_detect.RData")) {
  bpparam <- MulticoreParam(8) # for the cluster
  sp_afekta <- detect_signal(lab = "afekta", study_group = "HE", 
                             annotated = FALSE, bpparam = bpparam) # much better.
  save(sp_afekta, file = "object/sp_afekta.RData") ## trying to save some memory space. 
  rm(sp_afekta) 
  
  sp_hmgu <- detect_signal(lab = "hmgu", study_group = "HE",
                           annotated = FALSE, bpparam = bpparam) # 
  save(sp_hmgu, file = "object/sp_hmgu.RData")
  rm(sp_hmgu) 
  
  sp_icl <- detect_signal(lab = "icl", study_group = "HE",
                          annotated = FALSE, bpparam = bpparam)
  save(sp_icl, file = "object/sp_icl.RData")
  rm(sp_icl)
  
  sp_cembio <- detect_signal(lab = "cembio", study_group = "HE",
                             annotated = FALSE, bpparam = bpparam)
  save(sp_cembio, file = "object/sp_cembio.RData")
  
  
  load("object/sp_hmgu.RData")
  load("object/sp_afekta.RData")
  load("object/sp_icl.RData")
  
  sp_full_detect <- c(sp_afekta, sp_hmgu, sp_icl, sp_cembio)
  save(sp_full_detect, file = "object/sp_full_detect.RData")
  rm(sp_afekta, sp_hmgu, sp_icl, sp_cembio)
} else {
  load("object/sp_full_detect.RData")
}
```

Summarize the number of MS1 spectra per lab:

```{r}
table(sp_full_detect$lab) ## compare with sp_full 
```

Summarize the rtime range per lab (in seconds):

```{r}
lapply(split(rtime(sp_full_detect), sp_full_detect$lab) , range)
```

## Basic metrics 

Now baseline noise and spurious fluctuations are largely removed.

### Base Peak Chromatogram (BPC) area

We generate the BPC from the detected signal.

```{r}
if (!file.exists("object/bpc_detected.RData")) {
  bpc_detected <- Chromatograms(sp_full_detect, summarize.method = "max",
                       factorize.by= "dataOrigin", 
                       spectraVariables = c("lab", "mixture")) 
  bpc_detected <- setBackend(bpc_detected, ChromBackendMemory())
  save(file = "object/bpc_detected.RData", bpc_detected)
} else {
  load("object/bpc_detected.RData")
}
```

We summarize the BPC area per mixture per lab by summing the intensity values.

```{r}
sbpc <- vapply(intensity(bpc_detected), sum, numeric(1), na.rm = TRUE)
vioplot(log2(sbpc) ~ bpc_detected$lab, ylab = "Detected BPC area", xlab = "Lab")
```

Next, we compute the coefficient of variation (CV) per mixture across labs.

```{r}
cv_per_mix_det <- tapply(sbpc, bpc_detected$mixture, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE))
plot(cv_per_mix_det)
```

### Total Ion Current (TIC) area

```{r}
if (!file.exists("object/tic_detect.RData")) {
  tic_detect <- Chromatograms(sp_full_detect, summarize.method = "sum",
                       factorize.by= "dataOrigin",
                       spectraVariables = c("mixture", "lab")) 
  tic_detect <- setBackend(tic_detect, ChromBackendMemory())
  save(file = "object/tic_detect.RData", tic_detect)
} else {
  load("object/tic_detect.RData")
}
```

We summarize the TIC area per mixture per lab by summing the intensity values.

```{r}
stic <- vapply(intensity(tic_detect), sum, numeric(1), na.rm = TRUE)
boxplot(log2(stic) ~ tic_detect$lab, ylab = "TIC area (log2)", xlab = "Lab", 
        main = "Total ion signal across mixtures")
```

### ratio BPC / TIC

Now that we should have gotten rid of baseline and noise signal, the ratio 
should be properly describing the complexity of the detected signal.

```{r}
ratio_bpc_tic <- sbpc / stic
ratio_bpc_tic

vioplot(ratio_bpc_tic ~ tic_detect$lab, 
        ylab = "BPC / TIC area of detected signal", xlab = "Lab")
```

## tic/bpc ratio along rt 

Gives us some kind of chromatographic fingerprint per lab. 
Instead of baseline shape, you’re summarizing where peaks are detected along 
the gradient.

```{r ratio-detect, eval = TRUE}
ratio_all <- sapply(seq_along(tic_detect), function(i) {
  rt <- rtime(tic_detect[i])[[1]]
  int_tic <- log2(intensity(tic_detect[i])[[1]] + 1)  # +1 to avoid log2(0)
  int_bpc <- log2(intensity(bpc_detected[i])[[1]] + 1)
  
  # Bin retention time into 30 equal slices
  bins <- cut(rt, breaks = 30)
  
  # Compute median ratio BPC/TIC per bin
  tapply(seq_along(rt), bins, function(idx) {
    median(int_bpc[idx] / int_tic[idx], na.rm = TRUE)
  })
})

colnames(ratio_all) <- paste(tic_detect$lab, tic_detect$mixture, "pol:", tic_detect$polarity, sep = "_")
# Plot ratio for each mixture across labs
# | fig.width: 12
# | fig.height: 4

mixtures <- unique(tic_detect$mixture)
par(mfrow = c(1, 2))
for (mix in mixtures) {
  cols <- grep(mix, colnames(ratio_all))
  matplot(ratio_all[, cols], type = "b", pch = 1
    , xlab = "RT slices", ylab = "Median BPC/TIC ratio", main = paste("Mixture", mix))
 #  legend("topright", legend = colnames(ratio_all)[cols], col =
 # 1:length(cols), pch = 1)
}
```

## Chromatogram  Similarity

For this we use dtw, this measures baseline + peak shape similarity.
[insert more info about dtw and why we chose it here]

### Full data

- TIC

```{r dtw-tic-detect}
full_int <- intensity(tic_detect)

sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(tic_detect$lab, tic_detect$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(tic_detect$lab, tic_detect$mixture, sep = "_"),
  labCol = paste(tic_detect$lab, tic_detect$mixture, sep = "_"), main = "DTW similarity of TIC")
```


- BPC

```{r, dtw-bpc-full-detect}
full_int <- intensity(bpc_detected)

sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(bpc_detected$lab, bpc_detected$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(bpc_detected$lab, bpc_detected$mixture, sep = "_"),
  labCol = paste(bpc_detected$lab, bpc_detected$mixture, sep = "_"), main = "DTW similarity of BPC")
```


### ratio along retention time. 

Are all labs consistent across the whole gradient, or only in certain
RT regions?

```{r, dtw-ratio}
sim_matrix_med <- matrix(NA, ncol = ncol(ratio_all), nrow = ncol(ratio_all))
for (i in seq_len(ncol(ratio_all))) {
  for (j in seq_len(ncol(ratio_all))) {
    if (is.na(sim_matrix_med[i, j])) {
      dtw_res <- dtw(ratio_all[, i], ratio_all[, j], keep = FALSE)
      sim_matrix_med[i, j] <- dtw_res$normalizedDistance
      sim_matrix_med[j, i] <- sim_matrix_med[i, j]
    }
  }
}

## clustering
hc_med <- hclust(as.dist(sim_matrix_med))
plot(hc_med, labels = colnames(ratio_all), main = "DTW clustering of BPC/TIC ratio")

heatmap(sim_matrix_med, labRow = colnames(ratio_all),
  labCol = colnames(ratio_all), main = "DTW similarity of BPC/TIC ratio")
```

```{r}
## delete the memory hungry object 
rm(tic_detect, bpc_detected, sp_full_detect)
```

# Annotated signal

Here we will ONLY keep the annotated signal.

```{r}
## get this table from library generation
study_group <- "HE"
res_afekta <- read.csv(file.path("..", "afekta", "results",
                                 study_group, "ring_trial_library_HE.csv"))
res_hmgu <- read.csv(file.path(dr_hmgu, "results", 
                               study_group, "ring_trial_library_HE.csv"))
res_icl <- read.csv(file.path(dr_hmgu, "results", 
                               study_group, "ring_trial_library_HE.csv"))
res_cembio <- read.csv(file.path("..", "cembio", "results",
                                 study_group, "ring_trial_library_HE.csv"))
```


```{r, eval=I(!file.exists("object/sp_full_ann.RData"))}
sp_afekta <- detect_signal(lab = "afekta", study_group = study_group,
                           annotated = TRUE, bpparam = bpparam)
sp_hmgu <- detect_signal(lab = "hmgu", study_group = study_group, 
                         annotated = TRUE, bpparam = bpparam) 
sp_icl <- detect_signal(lab = "icl", study_group = study_group, 
                        annotated = TRUE, bpparam = bpparam)
sp_cembio <- detect_signal(lab = "cembio", study_group = study_group, 
                           annotated = TRUE, bpparam = bpparam)
sp_full_ann <- c(sp_afekta, sp_hmgu, sp_icl, sp_cembio) 
save(sp_full_ann, "object/sp_full_ann.RData")
```

```{r, eval=I(file.exists("object/sp_full_ann.RData"))}
load("object/sp_full_ann.RData")
```

```{r}
rm(sp_afekta, sp_hmgu, sp_icl)
```

Summarize the number of MS1 spectra per lab:

```{r}
table(sp_full_ann$lab) 
```

Summarize the rtime range per lab (in seconds):

```{r}
lapply(split(rtime(sp_full_ann), sp_full_ann$lab) , range)
```

## Basic metrics

### Base Peak Chromatogram (BPC) area

```{r, eval=I(!file.exists("object/bpc_ann.RData"))}
bpc_ann <- Chromatograms(sp_full_ann, summarize.method = "max",
                     factorize.by= "dataOrigin",
                     spectraVariables = c("mixture", "lab"))
bpc_ann <- setBackend(bpc_ann, ChromBackendMemory())
save(file = "object/bpc_ann.RData", bpc_ann)
```

```{r, eval= I(file.exists("object/bpc_ann.RData"))}
load("object/bpc_ann.RData")
```

We summarize the BPC area per mixture per lab by summing the intensity values.

```{r}
sbpc <- vapply(intensity(bpc_ann), sum, numeric(1))
vioplot(log2(sbpc) ~ bpc_ann$lab, ylab = "Detected BPC area", xlab = "Lab")
```

Next, we compute the coefficient of variation (CV) per mixture across labs.

```{r}
cv_per_mix_det <- tapply(sbpc, bpc_ann$mixture, function(x)
  sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE))
```

### Total Ion Current (TIC) area

```{r, eval=I(!file.exists("object/tic_ann.RData"))}
tic_ann <- Chromatograms(sp_full_ann, summarize.method = "sum",
                     factorize.by= "dataOrigin",
                     spectraVariables = c("mixture", "lab")) 
tic_ann <- setBacken  d(tic_ann, ChromBackendMemory())
save(file = "object/tic_ann.RData", tic_ann)
```

```{r}
load("object/tic_ann.RData")
```


We summarize the TIC area per mixture per lab by summing the intensity values.

```{r}
stic <- vapply(intensity(tic_ann), sum, numeric(1))
boxplot(log2(stic) ~ tic_ann$lab, ylab = "TIC area (log2)", xlab = "Lab", 
        main = "Total ion signal across mixtures")
```

### ratio BPC / TIC

Now we get the ratio for the spiked compound that were detected. 

```{r}
ratio_bpc_tic <- sbpc / stic
ratio_bpc_tic
vioplot(ratio_bpc_tic ~ tic_full$lab, 
        ylab = "BPC / TIC area of detected signal", xlab = "Lab")
```


## tic/bpc ratio along rt 

Gives us some kind of chromatographic fingerprint per lab.

```{r}
ratio_all <- sapply(seq_along(tic_ann), function(i) {
  rt <- rtime(tic_ann[i])[[1]]
  int_tic <- log2(intensity(tic_ann[i])[[1]] + 1)  # +1 to avoid log2(0)
  int_bpc <- log2(intensity(bpc_ann[i])[[1]] + 1)
  
  # Bin retention time into 30 equal slices
  bins <- cut(rt, breaks = 30)
  
  # Compute median ratio BPC/TIC per bin
  tapply(seq_along(rt), bins, function(idx) {
    median(int_bpc[idx] / int_tic[idx], na.rm = TRUE)
  })
})
```

```{r}
colnames(ratio_all) <- paste(tic_ann$lab, tic_ann$mixture, "pol:", tic_ann$polarity, sep = "_")
# Plot ratio for each mixture across labs
# | fig.width: 12
# | fig.height: 4

mixtures <- unique(tic_ann$mixture)
par(mfrow = c(1, 2))
for (mix in mixtures) {
  cols <- grep(mix, colnames(ratio_all))
  matplot(ratio_all[, cols], type = "b", pch = 1
    , xlab = "RT slices", ylab = "Median BPC/TIC ratio", main = paste("Mixture", mix))
 #  legend("topright", legend = colnames(ratio_all)[cols], col =
 # 1:length(cols), pch = 1)
}
```

## Chromatogram  Similarity

### Full data

- tic

```{r}
full_int <- intensity(tic_ann)

sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(tic_ann$lab, tic_ann$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(tic_ann$lab, tic_ann$mixture, sep = "_"),
  labCol = paste(tic_ann$lab, tic_ann$mixture, sep = "_"), 
  main = "DTW similarity of TIC")
```

- bpc

```{r}
full_int <- intensity(bpc_ann)

sim_matrix <- matrix(NA, ncol = length(full_int), nrow = length(full_int))

for (i in seq_along(full_int)) {
  for (j in seq_along(full_int)) {
    if (is.na(sim_matrix[i, j])) {
      dtw_res <- dtw(full_int[[i]], full_int[[j]], keep = FALSE)
      sim_matrix[i, j] <- dtw_res$normalizedDistance
      sim_matrix[j, i] <- sim_matrix[i, j]
    }
  }
}

# cluster 
hc <- hclust(as.dist(sim_matrix))
plot(hc, labels = paste(bpc_ann$lab, bpc_ann$mixture, sep = "_"), 
     main = "DTW clustering of TIC")

# heatmap 
heatmap(sim_matrix, labRow = paste(bpc_ann$lab, bpc_ann$mixture, sep = "_"),
  labCol = paste(bpc_ann$lab, bpc_ann$mixture, sep = "_"), 
  main = "DTW similarity of BPC")
```


### ratio along retention time.

```{r}
sim_matrix_med <- matrix(NA, ncol = ncol(ratio_all), nrow = ncol(ratio_all))
for (i in seq_len(ncol(ratio_all))) {
  for (j in seq_len(ncol(ratio_all))) {
    if (is.na(sim_matrix_med[i, j])) {
      dtw_res <- dtw(ratio_all[, i], ratio_all[, j], keep = FALSE)
      sim_matrix_med[i, j] <- dtw_res$normalizedDistance
      sim_matrix_med[j, i] <- sim_matrix_med[i, j]
    }
  }
}

# clustering
hc_med <- hclust(as.dist(sim_matrix_med))
plot(hc_med, labels = colnames(ratio_all), 
     main = "DTW clustering of BPC/TIC ratio")

# heatmap
heatmap(sim_matrix_med, labRow = colnames(ratio_all),
  labCol = colnames(ratio_all), main = "DTW similarity of BPC/TIC ratio")
```


# Background/other signal [to do later]

Here i need to load previous object and generate summary of "noise"

-   total signal - all detected peak signal

```{r}
load("object/tic_full.RData")
load("object/tic_detect.RData")

stic_full <- vapply(intensity(tic_full), sum, numeric(1))
stic_ann <- vapply(intensity(tic_detect), sum, numeric(1))

dif_int2 <- stic_full - stic_ann

vioplot(log2(dif_int2) ~ tic_full$lab, 
        ylab = "Total - detected TIC area", 
        xlab = "Lab")

```

-   total signal - annotated peak signal

```{r}
load("object/tic_ann.RData")
stic_ann <- vapply(intensity(tic_ann), sum, numeric(1))
dif_int3 <- stic_full - stic_ann
vioplot(log2(dif_int3) ~ tic_full$lab, 
        ylab = "Total - annotated TIC area", 
        xlab = "Lab")
```

- detected - annotated peak signal

This describe some "other signal": othger adduct, fragmentation, ...

```{r}
dif_int4 <- stic_detect - stic_ann
vioplot(log2(dif_int4) ~ tic_full$lab,
        ylab = "Detected - annotated TIC area", 
        xlab = "Lab")
```


# Peak analysis [ONGOING]

## Prep raw data 

I think I will extract from TIC full data. I want to take some extra data as 
"padding" around the detected peaks. 

### impute data 

I think it is better to do now than on specific peak ? 

```{r, eval = FALSE}
load("object/tic_full.RData")
missing_before <- sapply(intensity(tic_full), function(i) sum(is.na(i)))
tic_full@backend <- imputePeaksData(tic_full@backend, method = "linear")
missing_after  <- sapply(intensity(tic_full), function(i) sum(is.na(i)))

impute_metrics <- data.frame(
  chromatogram = seq_along(missing_before),
  missing_before = missing_before,
  missing_after  = missing_after,
  imputed = missing_before - missing_after
)

split(impute_metrics$imputed, tic_full$lab) |> lapply(summary)
```

### baseline correct

Same very much unsure though 

```{r, eval = FALSE}
tic_full <-  setBackend(tic_full, ChromBackendMemory())
intensity(tic_full) <- lapply(intensity(tic_full), function(i) {
  corrected <- ptw::baseline.corr(i, lambda = 200, p = 0.001)
  corrected[corrected < 0] <- 0   # set negatives to zero
  corrected
})

plot(intensity(tic_full[1])[[1]])
points(ptw::baseline.corr(intensity(tic_full[1])[[1]], 
                          lambda = 200, p = 0.001), col = "red")

```


### extract peaks 

THis whol ething can be simplified. go throuhg it. 
```{r, eval = FALSE}
## change order of things 
## - load 
## - add lab columns 
## - rbind 
## - add columns to full table. 

res_afekta$dataOrigin <- sampleData(mse)$spectraOrigin[chromPeaks(mse)[res_afekta$X, "sample"]] ## i htink I don't need htis. just use lab for chromExtract no ? 
res_afekta$lab <- "afekta"
res_hmgu$dataOrigin <- sampleData(mse_hmgu)$spectraOrigin[chromPeaks(mse_hmgu)[res_hmgu$X, "sample"]]


peak_table <- rbind(res_hmgu, res_afekta) 

#res_afekta$chromIndex <- seq_len(nrow(res_afekta)) ## nooope 
colnames(res_afekta)[1] <- "chrom_peak_id"
colnames(res_afekta)[4:7] <- c("mzMin", "mzMax", "rtMin", "rtMax")
res_afekta$mzMin <- res_afekta$mzMin - 0.005
res_afekta$mzMax <- res_afekta$mzMax + 0.005
res_afekta$rtMin <- res_afekta$rtMin - 5
res_afekta$rtMax <- res_afekta$rtMax + 5
res_afekta$msLevel <- 1L


res_hmgu$chromIndex <- seq_len(nrow(res_hmgu))
colnames(res_hmgu)[1] <- "chrom_peak_id"
colnames(res_hmgu)[4:7] <- c("mzMin", "mzMax", "rtMin", "rtMax")
res_hmgu$mzMin <- res_hmgu$mzMin - 0.005
res_hmgu$mzMax <- res_hmgu$mzMax + 0.005
res_hmgu$rtMin <- res_hmgu$rtMin - 5
res_hmgu$rtMax <- res_hmgu$rtMax + 5
res_hmgu$msLevel <- 1L
res_hmgu$lab <- "hmgu"
```




```{r, eval = FALSE}
## need to pool the peaks table and then probably have per file and per lab. 
## add all the other labs later
eics <- chromExtract(tic_full@backend, peak_table = peak_table,
                     by = c("dataOrigin", "lab")) ## add the variables wanted.
## need to fix the factors 
eics <- Chromatograms(eics)

chromData(eics)

## add some compound name and all 
chromData(eics) <- cbind(chromData(eics), 
                         peak_table[, !colnames(peak_table) %in% c("mz",
                         "chromIndex",  "rt", "dataOrigin", "lab", "rtMin",
                         "rtMax", "mzMin", "mzMax", "mixture", "msLevel")])

## remove peaks that have no datapoint 
idx_na <- which(sapply(intensity(eics), function(i) all(is.na(i))))
sum(idx_na)
save(file = "object/eics_detected.RData", eics)
```

-   number of peak per lab/ annotated adducts and annotated compound.

```{r, eval =FALSE}
## number of peak per lab 
table(peak_table$lab)

## number of compound per lab
split(peak_table$compound_name, peak_table$lab) |> 
  lapply(unique) |> 
  lapply(length)
```


### Clean eics

I need to clean the eics a bit. So the peaks metrics are fairly calculated.

smoothing first. 

window could be determine using the median of data points per peak. 
i would base the param choice on this, th emedian and minimum as well as some example on the data. 
al


```{r, eval = FALSE}
## lengths is not implemented for a Chromatograms object. 
# split by lab
eics_split <- split(eics, eics$lab)

results <- list()

for (lab in names(eics_split)) {
  x <- eics_split[[lab]]
  counts <- numeric(length(x))
  
  for (i in seq_along(x)) {
    counts[i] <- sum(!is.na(intensity(x[i])[[1]]))
  }
  
  results[[lab]] <- counts
}

# range for each lab 
vioplot(results)

summary_counts <- data.frame(
  lab = names(eics_split),
  mean_points = sapply(results, mean),
  min_points  = sapply(results, min),
  max_points  = sapply(results, max)
)

summary_counts
```


```{r, eval=FALSE}
int <- intensity(eics)
smooth_peak <- function(y, method = c("sgolay", "moving"), window = 5, poly = 2, idx = NA) {
  method <- match.arg(method)
  y[is.na(y)] <- 0
  
  if (all(y == 0) || length(y) < window) {
    warning(sprintf("EIC %s: skipped smoothing (all zeros or too short: n = %d)", idx, length(y)))
    return(y)
  }
  
  y_smooth <- tryCatch({
    if (method == "sgolay") {
      signal::sgolayfilt(y, p = poly, n = window)
    } else {
      zoo::rollmean(y, k = window, fill = "extend")
    }
  }, error = function(e) {
    warning(sprintf("EIC %s: smoothing failed — returning raw data. Error: %s", idx, e$message))
    y
  }, warning = function(w) {
    warning(sprintf("EIC %s: smoothing warning — returning raw data. Warning: %s", idx, w$message)) ## the  numbering does not work now of course but when implemented in Chromatograms hsould return the index of the eics failing. 
    y
  })
  
  # Clean up
  y_smooth[is.na(y_smooth)] <- 0
  y_smooth[y_smooth < 0] <- 0
  
  return(y_smooth)
}


plot(int[[3]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[3]], method = "sgolay", window = 9, poly = 2)
plot(new_peak)

plot(int[[39]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[39]], method = "sgolay", window = 9, poly = 2)
plot(new_peak)
new_peak <- keep_main_peak(new_peak)
plot(new_peak)


plot(int[[1]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[1]],method = "sgolay", window = 9, poly = 2)
plot(new_peak)
new_peak <- keep_main_peak(new_peak)
plot(new_peak)



plot(int[[1000]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[1000]],method = "sgolay", window = 9, poly = 2)
plot(new_peak)
new_peak <- keep_main_peak(new_peak)
plot(new_peak)


plot(int[[1500]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[1500]],method = "sgolay", window = 9, poly = 2)
plot(new_peak)
new_peak <- keep_main_peak(new_peak)
plot(new_peak)

plot(int[[1162]]) ## this should prob be smoothed beforehand. 
new_peak <- smooth_peak(int[[1162]],method = "sgolay", window = 9, poly = 2)
plot(new_peak)
new_peak <- keep_main_peak(new_peak)
plot(new_peak)
## mm ok let's see.
## 
int <- lapply(int, smooth_peak,  window = 9, poly = 2) ## this crashed but now i have a failsafe, if data is bad just return the raw one
```


hcekc if nsome have multiple peak wihtin them: 
this ufnction allow to keep the main peak. 

```{r}
keep_main_peak <- function(y, drop_frac = 0.05) {
  # Find main peak
  peaks <- pracma::findpeaks(y, sortstr = TRUE) ## find peak apex using local maxima 
  if (is.null(peaks)) return(y)
  
  main_center <- peaks[1, 2]
  apex <- y[main_center]
  n <- length(y)
  
  # Define adaptive cutoff: stop when intensity rises again or drops too low
  threshold <- apex * drop_frac
  
  # Extend left
  left <- main_center
  while (left > 1 && y[left - 1] < y[left] && y[left - 1] > threshold) {
    left <- left - 1
  }
  
  # Extend right
  right <- main_center
  while (right < n && y[right + 1] < y[right] && y[right + 1] > threshold) {
    right <- right + 1
  }
  
  # Create trimmed vector
  window <- left:right
  y_trimmed <- rep(0, n)
  y_trimmed[window] <- y[window]
  
  y_trimmed
}

plot(int[[39]])
new_peak <- keep_main_peak(int[[39]])
plot(new_peak)

## i want to test it on a different peak 

plot(int[[3]]) ## this should prob be smoothed beforehand. 
new_peak <- keep_main_peak(int[[3]])
plot(new_peak)

int_main_peak <- lapply(int, keep_main_peak)
```





- need to trim tail and pad. 

```{r}

## function below imply that the peaks are baseline correcte to 0. 
trim_and_extrapolate_peak <- function(y, extend = TRUE, extend_points = 3) {
  y <- as.numeric(y)
  y[is.na(y)] <- 0
  
  # Step 1: trim leading and trailing zeros
  nz <- which(y > 0)
  if (length(nz) == 0) return(numeric(0))
  start <- min(nz)
  end   <- max(nz)
  y_trim <- y[start:end]
  
  # Step 2: extrapolate to baseline if requested
  if (extend) {
    # left extrapolation (if signal starts above 0)
    if (y_trim[1] > 0) {
      left_ext <- y_trim[1] * exp(-seq(extend_points, 1, length.out = extend_points))
      left_ext <- left_ext - min(left_ext)  # ensure last one ~0
      left_ext[left_ext < 0] <- 0
      y_trim <- c(left_ext, y_trim)
    }
    
    # right extrapolation (if signal ends above 0)
    if (y_trim[length(y_trim)] > 0) {
      right_ext <- y_trim[length(y_trim)] * exp(-seq(1, extend_points, length.out = extend_points))
      right_ext <- right_ext - min(right_ext)
      right_ext[right_ext < 0] <- 0
      y_trim <- c(y_trim, rev(right_ext))
    }
  }
  
  # Step 3: ensure no negatives or NA
  y_trim[y_trim < 0] <- 0
  y_trim[is.na(y_trim)] <- 0
  
  return(y_trim)
}


## imp before this, i didn't really remove the "bad" eics. i would say, removing them before this should be good. 
## if no connection to baseline cna be found remove ? 

trimmed <- lapply(int_main_peak, trim_and_extrapolate_peak, extend = 1)

for (z in seq(length(int_main_peak)))
  res <- trim_and_extrapolate_peak(int_main_peak[[z]], extend = 1)


plot(intensity(eics)[[17]]) ## shit
plot(int[[17]])
plot(int_main_peak[[17]])
```

- remvoe "bad eics" 

```{r}
flag_bad_eics <- function(eics, snr_min = 5, width_min = 5) {
  bad_idx <- c()
  
  for (i in seq_along(eics)) {
    y <- as.numeric(eics[[i]])
    y[is.na(y)] <- 0
    
    # Skip flat/empty signals
    if (sum(y) == 0 || max(y) == 0) {
      bad_idx <- c(bad_idx, i)
      next
    }
    
    apex <- which.max(y)
    half <- max(y) / 2
    
    # find left/right crossing of half-height
    left <- max(1, tail(which(y[1:apex] <= half), 1))
    right <- apex - 1 + head(which(y[apex:length(y)] <= half), 1)
    if (is.na(right)) right <- length(y)
    width <- right - left + 1
    
    # simple SNR estimate
    baseline <- median(y[y > 0 & seq_along(y) < left], na.rm = TRUE)
    if (is.na(baseline)) baseline <- 0
    snr <- max(y) / (baseline + 1e-6)
    
    # flag criteria
    if (snr < snr_min || width < width_min) {
      bad_idx <- c(bad_idx, i)
    }
  }
  
  return(unique(bad_idx))
}


int_bad <- flag_bad_eics(trimmed) ## then cna manually decide to keep it or not ? 
int_bad
## here could plot all and manually decide which one ot keep or not. 

##then removed from trimmed.
##

##then repolace the intensity in the eics object 
##later on curate the peak analysis function 
## code should run all the way to here 
## 
```


### peak metrics summary
-   number of data points per peaks in each lab.

```{r, eval=TRUE}
## lengths is not implemented for a Chromatograms object. 
# split by lab
eics_split <- split(eics, eics$lab)

results <- list()

for (lab in names(eics_split)) {
  x <- eics_split[[lab]]
  counts <- numeric(length(x))
  
  for (i in seq_along(x)) {
    counts[i] <- sum(!is.na(intensity(x[i])[[1]]))
  }
  
  results[[lab]] <- counts
}

# range for each lab 
vioplot(results)

summary_counts <- data.frame(
  lab = names(eics_split),
  mean_points = sapply(results, mean),
  min_points  = sapply(results, min),
  max_points  = sapply(results, max)
)

summary_counts
```

```{r}
save.image("object/temp_work.RData")
```

-   peak width range and average




-   peak area range and average
-   peak height range and average
-   S/N ratio range and average:William
-   FWHM range and average
-   entropy range and average

for similarity comparison try zeros groupding, check rt scan order. 
or difference between each data point. I think this could work. 

could i filter the peaks for those that have more than one apex or something ? 
after imputation and smoothing of course. 



