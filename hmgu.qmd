---
title: "HMGU Reference Method Analysis - POS"
format: html
editor: visual
---

# Set up & raw data investigation

-   Workflow: HMGU Reference Method (Positive Mode)

-   Random notes:

    -   Need to ask for BLANK and NAPS next times.
    -   STRESS that we need centroided mode

## Load Required Packages

```{r, message=FALSE, warning=FALSE}
library(readxl)
library(S4Vectors)
library(MsExperiment)
library(xcms)
library(Spectra)
library(Biobase)
library(pheatmap)
library(alabaster.base)
library(MsIO)
library(RColorBrewer)
library(MetaboCoreUtils)
library(MetaboAnnotation)
library(pander)
```

## Load metadata and raw files

```{r, warning=FALSE, message=FALSE}
#' Load compound metadata (sheet 2);
#' skip variable renaming with .name_repair = "minimal"
meta_pos <- read_xlsx("data/hmgu/HMGU_RefMethod_HE.xlsx", sheet = 2L, 
                      col_names = TRUE, skip = 1, .name_repair = "minimal") |>
    as.data.frame(check.names = FALSE)
files_name <- unique(meta_pos$filname)
```

```{r, warning=FALSE, message=FALSE, eval=FALSE}
# Load pos data
seq <- read_xlsx("data/hmgu/HE_pos_mzml/seq.xlsx", 
                 col_names = TRUE) |> as.data.frame()
seq$filename <- paste0(seq$`Data File`, ".mzML")
mse_pos <- readMsExperiment(paste0("data/hmgu/HE_pos_mzml/", seq$filename), seq)
sampleData(mse_pos)

# load neg data
seq <- read_xlsx("data/hmgu/HE_neg_mzml/seq.xlsx", 
                 col_names = TRUE) |> as.data.frame()
seq$filename <- paste0(seq$`Data File`, ".mzML")
mse_neg <- readMsExperiment(paste0("data/hmgu/HE_neg_mzml/", seq$filename), seq)
```

```{r, eval=FALSE}
#' Set up parallel processing using 2 cores
if (.Platform$OS.type == "unix") {
    register(MulticoreParam(2))
} else {
    register(SnowParam(2))
}
```

## Overview and Quality

suggestion to extract the BPC of all samples and plot them, all in one. BPC

```{r, eval=FALSE}
#| fig-height: 8
#| fig-width: 6
col_sample_type <- brewer.pal(
    n = max(3, length(unique(sampleData(mse_pos)$sample_type))), "Set2")
names(col_sample_type)[seq_along(unique(sampleData(mse_pos)$sample_type))] <-
    unique(sampleData(mse_pos)$sample_type)
bpc_pos <- chromatogram(mse_pos, aggregationFun = "max")
bpc_neg <- chromatogram(mse_neg, aggregationFun = "max")

par(mfrow = c(2, 1))
plot(bpc_pos, col = paste0(col_sample_type[bpc_pos$sample_type], 80))
grid()
legend("topright", col = col_sample_type, lwd = 1,
       legend = names(col_sample_type))
plot(bpc_neg, col = paste0(col_sample_type[bpc_neg$sample_type], 80))
grid()
```

Observations:

-   naps seem to be measured in regular intervals (but with different
    intensities) between \~ 200 and 600 seconds.
-   some peaks seem to be sample file-specific - which is actually what we
    would expect, since this should represent the signal from the spiked
    (added) standard.

- should we use NAPS for alignment between POS and NEG samples ?
- If we do not align, we could just have a accepted RT threshold high ? 

Comment:

-   Similarity between LC runs (i.e. BPC or TIC similarities) might not be that
    informative: we expect the NAPS to be very similar, but the samples with
    the spiked compounds are expected to be quite different (because different
    compounds are present).
      - I mean we expect the NAPS to be similar but what if they are not ? 
        and difference in NAPS between labs is also interesting. 
-   Otherwise, similarity could/should be calculated on the full data set
    (NAPS + samples) to reduce the number of plots shown.

BPC - samples

```{r, eval=FALSE}
idx_sample_pos <- sampleData(mse_pos)$sample_type == "sample"
idx_sample_neg <- sampleData(mse_neg)$sample_type == "sample"
```

```{r, eval=FALSE}
chromatogram(mse_pos[idx_sample_pos], msLevel = 1L, chunkSize =2 ) |> 
  plot(main = "BPC sample positive ionization")

chromatogram(mse_neg[idx_sample_neg], msLevel = 1L, chunkSize = 2) |>
  plot(main = "BPC sample negative ionization")
```

BPC NAPS.

```{r, eval=FALSE}
idx_NAPS_pos <- sampleData(mse_pos)$sample_type == "NAPS"
chromatogram(mse_pos[idx_NAPS_pos], msLevel =1, chunkSize = 2) |> 
  plot(main = "BPC NAPS positive ionization")

idx_NAPS_neg <- sampleData(mse_neg)$sample_type == "NAPS"
chromatogram(mse_neg[idx_NAPS_neg], msLevel =1, chunkSize = 2) |>
  plot(main = "BPC NAPS negative ionization")

## i would do a separate object with NAPS for each lab. - for comparison
## it's supposed to have 20 peaks
```

There does not seem to be a big shift in retention time BUT In intensity yes.

- Is it linked to injection index ?

TIC matrix similarity of NAPS.

```{r, eval=FALSE}
#' Total ion chromatogram
tic <- chromatogram(mse_pos[idx_NAPS_pos], 
                    aggregationFun = "sum", msLevel = 1L, chunkSize = 2) |>
  bin(binSize = 2)
#' Calculate similarity (Pearson correlation) between TICs
ticmap <- do.call(cbind, lapply(tic, intensity)) |>
  cor()
rownames(ticmap) <- colnames(ticmap) <- sampleData(mse_pos[idx_NAPS_pos])$Sample.Name
pheatmap(ticmap,
         main = "TICs similarity of NAPS sample, positive ionization")

#' Neg mode
tic <- chromatogram(mse_neg[idx_NAPS_neg], 
                    aggregationFun = "sum", msLevel = 1L, chunkSize = 2) |>
  bin(binSize = 2)
ticmap <- do.call(cbind, lapply(tic, intensity)) |>
  cor()
rownames(ticmap) <- colnames(ticmap) <- sampleData(mse_neg[idx_NAPS_neg])$Sample.Name
pheatmap(ticmap,
         main = "TICs similarity of NAPS sample, negative ionization")

##have NA here I need to figure it out
```

Not as similar as I would expect. But in the paper they are normalized soo.

BPC blanks:

```{r, eval=FALSE}
idx_blank_pos <- sampleData(mse_pos)$sample_type == "blank"
chromatogram(mse_pos[idx_blank_pos], msLevel = 1L, chunkSize = 2) |> 
  plot(col = c("blue", "red"), main = "BPC blank positive ionization")

idx_blank_neg <- sampleData(mse_neg)$sample_type == "blank"
chromatogram(mse_neg[idx_blank_neg], msLevel = 1L, chunkSize = 2) |> 
  plot(col = c("blue", "red"), main = "BPC blank negative ionization")
```

RT ranges and spectra number per MS levels:

```{r, eval=FALSE}
#' Range
range(rtime(mse_pos))
range(rtime(mse_neg))

#' Count the number of spectra with a specific MS level per file.
print("Positive mode")
spectra(mse_pos) |>
    msLevel() |>
    split(fromFile(mse_pos)) |>
    lapply(table) |>
    do.call(what = cbind)

#' Count the number of spectra with a specific MS level per file.
print("Negative mode")
spectra(mse_neg) |>
    msLevel() |>
    split(fromFile(mse_neg)) |>
    lapply(table) |>
    do.call(what = cbind)
```

Comments: Nothing alarming. Similar-ish number of spectra. I would not do
filtering for now.

-   Here decide if want to filter retention time (method dependent), if yes
    run:

```{r}
# mse <- filterRt(mse, rt = c(0, 60)) ## change c(0,60) to your settings
```

# Workflow explanation

!!! To be re-done with new workflow. 

```{r}
#| code-fold: true
#| code-summary: "Show the code"
library(DiagrammeR)

grViz("
digraph sample_analysis {
  graph [layout = dot, rankdir = TB]

  node [shape = box, style = filled, color = lightgray, fontname = Helvetica]

  LoadSample      [label = '1. One sample/One mixture']
  EstimateParams  [label = '2. Estimate Peak Picking Params']
  PeakPicking     [label = '3. Perform Peak Picking on ALL samples']
  MatchStandards  [label = '4. Match peaks to Standards (Theoretical m/z)']
  MultiPeak       [label = '5. Deal with multiple chrom peaks for same m/z']
  rtgroup         [label = '6. Group by RT across adducts']
  Visualize       [label = '7. Visualize EICs for standards']
  ExtractMS2      [label = '5. Extract MS2 for ALL chromatographic Peaks']
  NonMatched      [label = '6. MS2 Annotation using GNPS library']
  VisMS2          [label = '7. Visualize fragment matching to ref library']
  VisMS1          [label = '5. Visualize MS1 for standards']
  isotope         [label = '6. Isotope pattern matching']
  
  LoadSample -> EstimateParams -> PeakPicking -> MatchStandards
  MatchStandards -> MultiPeak
  rtgroup -> Visualize
  MultiPeak -> rtgroup
  MatchStandards -> ExtractMS2
  ExtractMS2 -> NonMatched -> VisMS2
  MatchStandards -> VisMS1 -> isotope
}
")
```

# Estimate peak-picking parameters on ONE file.

```{r, eval=FALSE}
sp_meta <- split(meta_pos, meta_pos$filname)
x_meta <- sp_meta[[1]]
x_mse <- mse_pos[idx_sample_pos][1]
```

## Extract theoretical EICs

Using theoretical m/z for both main positive adducts and all along the
retention time.

```{r, eval=FALSE}
#| code-fold: true
#| code-summary: "Show the code"

#' Calculate m/z from the exact mass
theo_mz <- mass2mz(x_meta[, "M"], c("[M+H]+", "[M+Na]+")) |>
    as.vector()
#' Define the m/z range.
theo_mzr <- cbind(mzmin = theo_mz - MsCoreUtils::ppm(theo_mz, 20),
                  mzmax = theo_mz + MsCoreUtils::ppm(theo_mz, 20))
#' Expand by a fixed tolerance.
theo_mzr[, 1L] <- theo_mzr[, 1L] - 0.005
theo_mzr[, 2L] <- theo_mzr[, 2L] + 0.005
eicsMH <- chromatogram(x_mse, mz = theo_mzr)

#' would use the ID + adduct as file name.
fData(eicsMH)$std_id <- paste0(rep(x_meta$ChEBI, 2), "-", 
                               rep(c("[M+H]+", "[M+Na]+"), each = nrow(x_meta)))
fData(eicsMH)$std_name <- paste0(rep(x_meta$`ChEBI name`, 2), "-", 
                               rep(c("[M+H]+", "[M+Na]+"), each = nrow(x_meta)))
rownames(eicsMH) <- fData(eicsMH)$std_id

dr <- "res/hmgu/eics_full_rt_slices/M_ions/"
dir.create(dr, recursive = TRUE, showWarnings = FALSE)
for (i in seq_along(eicsMH)) {
    png(paste0(dr, "EIC_", fData(eicsMH)$std_id[i], ".png"),
        width = 12, height = 8, units = "cm", res = 600, pointsize = 4)
    plot(eicsMH[i, ], main = fData(eicsMH)$std_name[i])
    legend("topright",
           legend = c(mzmin = format(fData(eicsMH)$mzmin[i], digits = 6),
                      mzmax = format(fData(eicsMH)$mzmax[i], digits = 6)))
    grid()
    dev.off()
}

```

We have `r length(theo_mz)` number of standard.

After a quick check they seem pretty noisy, and they all have more than one
very big peak.

## Peak picking param set up

Use the previous EICs to set up parameters. This should happen only once per
lab.

First quickly checking a few peaks to look for peak width:

```{r, eval=FALSE}
plot(eicsMH["CHEBI:15611-[M+Na]+"], xlim = c(0, 30)) # 6secs
plot(eicsMH["CHEBI:16856-[M+H]+"], xlim = c(10, 50)) # 10s 
plot(eicsMH["CHEBI:15699-[M+H]+"], xlim = c(20, 40)) #7s 
```

Will set up for `c(4, 12 seconds)` peak-width. Noise seems to be fairly low.
Maybe a cut-off around 200 to prevent bad peaks to be detected, could be
implemented. The intensity are super low for some standard however.

For ppm deviation:

```{r, eval=FALSE}
mz <- mz(eicsMH["CHEBI:15699-[M+H]+"]) |> as.vector()
cst <- x_mse |>
    spectra() |>
    filterMsLevel(msLevel = 1L) |>
    filterRt(rt = c(25, 27)) |>
    filterMzRange(mz = mz)

x_mse |>
    filterMsLevel(1L) |>
    filterRt(c(18, 30)) |>
    filterMzRange(mz = mz) |>
    plot()

#' Show the number of peaks per m/z filtered spectra
lengths(cst)
```

```{r, eval=FALSE}
#' Calculate the difference in m/z values between scans
mz_diff <- cst |>
    mz() |>
    unlist() |>
    diff() |>
    abs()

#' Express differences in ppm
range(mz_diff * 1e6 / mean(unlist(mz(cst))))
```

Set up at 5ppm. mm Johannes increased to 20ppm

# Peak picking on ALL samples

Comment:

-   I would run a rather inclusive peak detection. We could filter/restrict the
    data set later.

```{r,eval=FALSE}
param <- CentWaveParam(peakwidth = c(4, 12), ppm = 20, integrate = 2,
                       snthresh = 7, noise = 100) 

mse_pos <- findChromPeaks(mse_pos[idx_sample_pos], param, 
                          msLevel = 1L, chunkSize = 2L)
mse_neg <- findChromPeaks(mse_neg[idx_sample_neg], param,
                          msLevel = 1L, chunkSize = 2L)

param <- MergeNeighboringPeaksParam(expandRt = 6, expandMz = 0.0015,
                                    minProp = 0.75)
mse_pos <- refineChromPeaks(mse_pos, param, chunkSize = 2L)
print("Positive mode:")
chromPeakData(mse_pos)$merged |>
                         table() 

mse_neg <- refineChromPeaks(mse_neg, param, chunkSize = 2L)
print("Negative mode:")
chromPeakData(mse_neg)$merged |>
                      table()

# saveMsObject(mse_pos,
#              AlabasterParam(path = file.path("res/hmgu/objects/mse_pos")))
# saveMsObject(mse_neg,
#              AlabasterParam(path = file.path("res/hmgu/objects/mse_neg")))
```

Some comments: 

- I am struggling with the noise settings. Pauline tells me she had it set up at
500 on mzmine. but with 500 i get only 55% of the standard detected. and she
gets much more.
- This also mean the technique is maybe not the best (we prob should NOT have 
  such low abundances.)
- So either we go for NO noise threshold and then deal with things that are just
  noise later on. or we accept we miss the low abundance peak and this gives just
  a actually view of the analytical platform maybe not being great for this (or
  samples were too diluted.)


# Library building

Below I load the files that have been preprocessed. There they have 
chromatographic peaks detected. 

```{r}
# load 
mse_pos <- readMsObject(XcmsExperiment(), 
                  AlabasterParam(path = file.path("res/hmgu/objects/mse_pos")), 
                  spectraPath = file.path("data/hmgu/HE_pos_mzml/"))

mse_neg <- readMsObject(XcmsExperiment(),
                  AlabasterParam(path = file.path("res/hmgu/objects/mse_neg")), 
                  spectraPath = file.path("data/hmgu/HE_neg_mzml/"))
```

Manually evaluating the data for one compound. We could apply/run the same code
on all assigned chromatographic peaks to add additional evidence. 
What evidences, ideally orthogonal ones, could we use? 
The goal is to identify the signal along the retention time dimension that 
*most likely* represents the signal of the spiked standard. A first selection
on m/z identifies the chrompeaks that could represent the signal from the
respective compound. Then, we should add additional information that helps 
deciding whether the signal is *really* from the standard. Ideally, collect 
as much information as possible to allow better estimation/validation of the
signal. The workflow could be the following:

-   identify chromatographic peaks matching m/z of expected/potential ions.
-   for each chromatographic peak:
    -   get MS2 spectra, match them against *all* reference spectra (all
        compounds).
    -   get MS1 spectrum:
        -   report similarity of isotope pattern against theoretical one.
        -   identify number of adduct ions present.
-   for each standard: group chromatographic peaks (between the different
    adducts) along retention time to identify retention time regions with
    signal of the ions.
-   for each of these regions: (per region or RT,...)
    -   count number of chrom peaks/adducts.
    -   ratio between total and matched number of MS2 spectra.
        -   number of MS2 per peak / matched

At the end, each standard as a number of rows matching the number of regions.
and each of these regions have a number of columns with evidence that the 
user can use to make a decision. 

What information could be used to make an educated guess:

-   low evidence: isotope pattern matching - would be just confirmation that
    the chemical formula is the expected one, so *only* confirming the match
    based on the m/z.
-   low confidence: signal from multiple ions of the compound - but this can
    not be generalized across compounds as it depends on a variety of factors.
    -   Also to get as much data as possible, need to check the pos and neg
        adducts together.
-   highest confidence: (multiple) MS2 spectra match reference. But even if
    there is no match we can't be sure that it is not the compound. The
    compound might be missing in the reference database.
-   log-p NAPS
    -   NAPS peak number before and after

When performing this automatically i will need to split the object and the
metadata mixture by mixture. To set up the process right now I will just do it
for one mixture.

```{r}
# subset
sp_meta <- split(meta_pos, meta_pos$filname)
x_meta <- sp_meta[[1]]
x_mse_pos <- mse_pos[1]
x_mse_neg <- mse_neg[1]
```

We use below functionality from the *MetaboAnnotation* package to
match/annotate the identified chromatographic peaks against the expected target
compounds.

##  Identify chrom peaks matching ions/adducts of the standards

```{r}
#' x_mse_pos XcmsExperiment
#' x_meta data.frame with the standards expected to be present

#' 1) match chrom peaks to possible ions
cpks <- as.data.frame(chromPeaks(x_mse_pos))
cpks$chrom_peak_id <- rownames(cpks)

adds <- c("[M+H]+", "[M+Na]+", "[M+H-H2O]+") ## easily scalable 
x_match <- matchValues(cpks, x_meta,
                       Mass2MzParam(adds, tolerance = 0.05, ppm = 10), 
                       mzColname = "mz", massColname = "M")
```

We next extract and further process/expand the result data frame.

```{r}
#' Extract the matching result.
x_match <- x_match[whichQuery(x_match)]
x_match_res <- matchedData(
    x_match, c("chrom_peak_id", "rtmin", "rtmax", "into", "target_ChEBI name",
               "target_ChEBI", "target_InChIKey", "target_formula", "target_M",
               "adduct", "score", "ppm_error")) |> as.data.frame()
#' Add the m/z of the adduct
x_match_res$adduct_mz <- mapply(x_match_res$target_M, x_match_res$adduct,
                                FUN = mass2mz)
#' Calculate the chemical formula of the adduct
af <- mapply(x_match_res$target_formula, x_match_res$adduct,
             FUN = adductFormula)
adductCharge <- function(x) {
    MetaboCoreUtils:::.process_adduct_arg(x, "charge")
}
af <- gsub("^\\[|\\].*$", "", af)
x_match_res$adduct_formula <- af

# again do we have peak that match multiple standard?
any(duplicated(x_match_res$chrom_peak_id))
```

##  Process each chrom peak

First process the MS1 data:

-   extract full scan MS1 for each chrom peak.
-   identify all mass peaks that could be the signal of one ion/adduct of the
    compound.

```{r}
x_match_ms1 <- chromPeakSpectra(
    x_mse_pos, msLevel = 1L, peaks = x_match_res$chrom_peak_id,
    method = "closest_rt")
x_match_ms1$exactmass <- x_match_res$target_M
x_match_ms1$adduct_mz <- x_match_res$adduct_mz

x_match_ms1 <- setBackend(backend = MsBackendMemory(), object = x_match_ms1)


#' determine which other adduct peaks would be present in the MS1 spectrum.
x_match_ms1_adducts <- spectrapply(x_match_ms1, function(z) {
    mzs <- sort(mass2mz(z$exactmass, adductNames("positive"))[1, ]) ## here should we restrict to certain adducts ? 
    z <- filterMzValues(z, mzs, ppm = 10)
    idx <- MsCoreUtils::closest(mz(z)[[1L]], mzs)
    z$peak_adduct_name <- list(names(mzs)[idx])
    z <- applyProcessing(z)
    z
})
x_match_ms1_adducts <- concatenateSpectra(x_match_ms1_adducts)

#' we add this information to the result table for each chrom peak
x_match_res$ms1_adduct_count <- lengths(x_match_ms1_adducts)
#' In addition we add the number of adducts that have an intensity >= 0.5 the
#' intensity of the chrom peak's intensity.
x_match_res$ms1_adduct_05_count <- spectrapply(
    x_match_ms1_adducts, function(z) {
        adct <- x_match_res[z$chrom_peak_id, "adduct"]
        idx <- which(z$peak_adduct_name[[1L]] == adct)
        sum(intensity(z)[[1L]] >= 0.5 * intensity(z)[[1L]][idx])
    }) |> unlist()
```

We plot these to file. An example plot is shown below.

```{r}
#' Plot example
a <- x_match_ms1_adducts[1]
cmp <- x_match_res[a$chrom_peak_id, "target_ChEBI"]
adct <- x_match_res[a$chrom_peak_id, "adduct"]

plotSpectra(a, labels = a$peak_adduct_name, labelSrt = 30,
            labelPos = 4, labelOffset = 0.1,
            main = paste(cmp, a$chrom_peak_id, adct, "RT:", rtime(a)))
#' highlight the actual adduct of the chrom peak.
idx <- which(a$peak_adduct_name[[1L]] == adct)
points(mz(a)[[1L]][idx], intensity(a)[[1L]][idx], col = "#00ceff",
       type = "h")
grid()

#' Plot all
dr <- file.path("res", "test")
dir.create(dr, recursive = TRUE, showWarnings = FALSE)
for (i in seq_along(x_match_ms1_adducts)) {
    a <- x_match_ms1_adducts[i]
    cmp <- x_match_res[a$chrom_peak_id, "target_ChEBI"]
    ## her sub ":" for "_"
    cmp <- gsub(":", "_", cmp)
    adct <- x_match_res[a$chrom_peak_id, "adduct"]
    f <- png(paste0(dr, "/", cmp, "-", a$chrom_peak_id, "-ions.png"),
             width = 8, height = 8, units = "cm", res = 600, pointsize = 4)
    plotSpectra(a, labels = a$peak_adduct_name, labelSrt = 30,
                labelPos = 4, labelOffset = 0.1,
                main = paste(cmp, a$chrom_peak_id, adct, "RT:", rtime(a)))
    idx <- which(a$peak_adduct_name[[1L]] == adct)
    points(mz(a)[[1L]][idx], intensity(a)[[1L]][idx], col = "#00ceff",
           type = "h")
    grid()
    dev.off()
}
```

We next validate for each of the identified/assigned chromatographic peaks
whether the measured isotope pattern matches the theoretical isotope pattern
for the ion (its chemical formula).

```{r}
library(enviPat)
data(isotopes)

#' For each MS1 spectrum, extract the peaks matching potential isotope peaks.
#' determine which other adduct peaks would be present in the MS1 spectrum.
x_match_ms1_isopeaks <- spectrapply(x_match_ms1, function(z) {
    idx <- isotopologues(peaksData(z)[[1L]], ppm = 20, seedMz = z$adduct_mz)
    if (length(idx) == 1L)
        res <- addProcessing(z, function(x, i = idx[[1L]], ...) {
            x[i, , drop = FALSE]
        })
    else
        res <- filterMzValues(z, mz = z$adduct_mz, ppm = 20, tolerance = 0)
    applyProcessing(res)
}) |>
    concatenateSpectra() |>
    scalePeaks()

#' Create theoretical isotope pattern for all chrom peaks/adducts
adductCharge <- function(x) {
    MetaboCoreUtils:::.process_adduct_arg(x, "charge")
}
ip <- isopattern(
    isotopes, check_chemform(isotopes, x_match_res$adduct_formula)$new_formula,
    threshold = 0.001, charge = adductCharge(x_match_res$adduct), rel_to = 2)

#' Create a Spectra with the isotope pattern for each chemical formula.
isopattern_to_spectra <- function(x) {
    df <- data.frame(msLevel = 1L, formula = names(x))
    df$mz <- lapply(x, function(z) z[, 1L])
    df$intensity <- lapply(x, function(z) z[, 2L])
    Spectra(df)
}
ms1_theoretical_isopeaks <- isopattern_to_spectra(ip)
```

We next calculate the similarity between the *measured* isotope peak pattern
for each chromatographic peak and the theoretical isotope pattern calculated
based on the adduct formula. In addition we create mirror plots for all pairs -
one example is shown below.

```{r}
plotSpectraMirror(x_match_ms1_isopeaks[4],
                  ms1_theoretical_isopeaks[4], ppm = 20,
                  main = paste(x_match_res$target_ChEBI[4],
                               x_match_res$chrom_peak_id[4],
                               x_match_res$adduct[4]))

#' Add isotope similarity information
x_match_res$isopeak_count <- lengths(x_match_ms1_isopeaks)
x_match_res$isopeak_sim <- diag(
    compareSpectra(x_match_ms1_isopeaks, ms1_theoretical_isopeaks, ppm = 20))

for (i in seq_along(x_match_ms1_isopeaks)) {
    f <- png(paste0(dr, "/", x_match_res$target_ChEBI[i], "-",
                    x_match_res$chrom_peak_id[i], "-isotope-pattern.png"),
             width = 8, height = 8, units = "cm", res = 600, pointsize = 4)
    plotSpectraMirror(x_match_ms1_isopeaks[i],
                      ms1_theoretical_isopeaks[i], ppm = 20,
                      main = paste(x_match_res$target_ChEBI[i],
                                   x_match_res$chrom_peak_id[i],
                                   x_match_res$adduct[i]))
    grid()
    dev.off()

}
```

**Isotopes**: comparing the observed against the theoretical isotope pattern
for a chrom peak (or feature) to compound assignment could provide additional
evidence for the match. The isotope pattern would base exclusively by the
chemical formula and could be easily calculated with the *enviPat* R package.
Note however, that this would **not** help with isomers (i.e. different
compounds with same m/z eluting at different time) as their chemical formula is
expected to be the same. Also, isotope peaks are expected to be detected only
for high intensity signals, as the signal might be below detection limits
otherwise.


## MS2 annotation

- output should be quantification of number of MS2 spectra per chrompeaks, 
  number of positive match, and number of TRUE positive match.
- Another output should be the mirror plot with name of compound at the top. 

```{r}
ms2peaks <- chromPeakSpectra(x_mse_pos, method = "all", 
                             expandRt = 2, expandMz = 0.01, ## too loose ? 
                             peaks = rownames(x_match_res) ,
                             chromPeakColumns = c("rt", "mz", "mzmin",
                                                  "mzmax", "rtmin", "rtmax",
                                                  "into")) 

## here could also filter to only keep the M+H+ ions as ref library mostly have 
## that

## append number of MS2 to the result table
x_match_res[unique(ms2peaks$chrom_peak_id), "ms2_count"] <- table(ms2peaks$chrom_peak_id)

## clean ms2. 
#' Remove low intensity peaks
low_int <- function(x, ...) {
    x > max(x, na.rm = TRUE) * 0.05
}
# full ms2 data 
ms2peaks <- filterIntensity(ms2peaks, intensity = low_int)
#' Remove precursor peaks and restrict to spectra with a minimum
#' number of peaks
ms2peaks <- filterPrecursorPeaks(ms2peaks, ppm = 50, mz = ">=")
ms2peaks <- ms2peaks[lengths(ms2peaks) > 1] |>
    scalePeaks()

ms2peaks <- setBackend(backend = MsBackendMemory(), object = ms2peaks)
ms2peaks <- applyProcessing(ms2peaks)
```

Apply the same to the ref database.

```{r}
library(RSQLite)
library(MsBackendSql)
dbfile <- "MsBackendSql.GNPS.matchms.cleaned.v1.sqlite"
con <- dbConnect(SQLite(), dbfile)
ms2_ref <- Spectra(con, source = MsBackendSql())

## szubset for expected compounds
# idx <-  which(mb$inchikey %in% x_meta$InChIKey) for now no
# ms2_ref <- mb[idx]
ms2_ref <- ms2_ref[ms2_ref$polarity == 1,]

ms2_ref <-  filterIntensity(ms2_ref, intensity = low_int) |>
    filterPrecursorPeaks(ppm = 50, mz = ">=")

ms2_ref <- ms2_ref[lengths(ms2_ref) > 1] |>
     scalePeaks()

ms2_ref <- setBackend(backend = MsBackendMemory(), object = ms2_ref)
ms2_ref <- applyProcessing(ms2_ref)
```

```{r}
prm <- CompareSpectraParam(ppm = 40, tolerance = 0.05,
                           requirePrecursor = TRUE,
                           THRESHFUN = function(x) which(x >= 0.6))

ms2peaks_mtch <- matchSpectra(ms2peaks, ms2_ref, param = prm)
ms2peaks_mtch
```

```{r}
ms2_mtch <- ms2peaks_mtch[whichQuery(ms2peaks_mtch)]

df <- matchedData(ms2_mtch)[, c("target_compound_name",
                                       "target_inchikey", "score", "chrom_peak_id", ".original_query_index", "target_adduct")]
df$target_index <- targetIndex(ms2_mtch)
df$query_index <- queryIndex(ms2_mtch)
df <-
    df |>
    split(f = paste(df$chrom_peak_id, df$target_inchikey)) |>
    lapply(function(z) {
        z[which.max(z$score), ]
    }) |>
    do.call(what = rbind) |>
    as.data.frame()

df <- as.data.frame(df)
pandoc.table(df,
             style = "rmarkdown",
             split.table = Inf)

## append number of spectra that have at least one match. 
## need to use the columns .original_query_index and chrom_peak_id
try <- df[!duplicated(df$.original_query_index), ]
x_match_res[unique(try$chrom_peak_id), "ms2_matched_count"] <- table(try$chrom_peak_id)

## now need to check using inchiKey if it's a TRUE positive identification
## onlly match first partt of inchikey, using sub("-.*", "", x)
true <- df[sub("-.*", "", df$target_inchikey) %in% sub("-.*", "", x_meta$InChIKey), ]
## add standnard name 
true <- merge(true, x_match_res[, c("target_ChEBI.name", "chrom_peak_id")],
              by = "chrom_peak_id")
x_match_res[unique(true$chrom_peak_id), "ms2_true_count"] <- table(true$chrom_peak_id)
```


```{r}
## plot 
i <- true$.original_query_index[1]
j <- true$target_index[1]
query_ms2 <- query(ms2_mtch)[i]
target_ms2 <- target(ms2_mtch)[j] #i am not sure this works properly 

plotSpectraMirror(query_ms2, target_ms2, main = true$target_ChEBI.name[1])

for (i in seq_len(nrow(true))) {
    f <- png(paste0(dr, "/", true$target_ChEBI.name[i], "-",
                    true$chrom_peak_id[i], "-ms2.png"),
             width = 8, height = 8, units = "cm", res = 600, pointsize = 4)
    query_ms2 <- query(ms2_mtch)[true$query_index[i]]
    target_ms2 <- target(ms2_mtch)[true$target_index[i]]
    plotSpectraMirror(query_ms2, target_ms2,
                      main = paste(true$target_ChEBI.name[i],
                                   true$chrom_peak_id[i]))
    grid()
    dev.off()
}
```

Ok so there are probably more things to do but pretty nice for now. 
Also GNPS has some adducts info. Would be nice to quickly check that. 


## RT grouping 

Now we would go through each standards. and create regions info/concatenate 
results based on RT regions. 

- RT grouping 
  - define regions of interest. 
  - combine results for peaks of same region.

```{r}
library(MsFeatures)
## below we group based on RT
sp_res <- split(x_match_res, x_match_res$target_ChEBI.name)
x_match_res <- apply(sp_res, function(z) {
    rts  <- chromPeaks(x_mse_pos)[z$chrom_peak_id, "rt"]
    param <- SimilarRtimeParam(diffRt = 10, groupFun = groupClosest)
    groups <- groupFeatures(rts, param)
    z$rt_regions <- as.numeric(groups)
    z
}) |> 
    do.call(what = rbind) |>
    as.data.frame()
```

oki now goruped we can work/summarize "per standard"

```{r}
## concatenate below 
## - need to go through each group, add number of peaks, concatenate peakId, 
## and all the results per peaks.
##  - do we have anything that is not quantified beside the peaks id ?
##  rt_region 
##  the columns starting with "target-" are identical for compound of the same stndard 
##  rtmin: take the min 
##  rtmax: take the max
##  adduct, chrompeak_id: concatenate with |
##  into: average
##  score : what is it ????
##  ms1_adduct_count: add 
##  ms1_adduct_05_count: add
##  isopeak_count: add
##  isopeak_sim: average
##  ms2_count: add
##  ms2_matched_count: add
##  ms2_true_count: add
## test on x_res 

split(x_res, x_res$rt_region) |>
    lapply(function(z) {
        idx_rmv <- colnames(z) %in% c("adduct_formula", "adduct_mz")
        res <- z[1, !idx_rmv]
        res$chrom_peak_id <- paste(z$chrom_peak_id, collapse = "|")
        res$adduct <- paste(z$adduct, collapse = "|")
        res$rtmin <- min(z$rtmin)
        res$rtmax <- max(z$rtmax)
        res$into <- mean(z$into)
        res$ms1_adduct_count <- sum(z$ms1_adduct_count)
        res$ms1_adduct_05_count <- sum(z$ms1_adduct_05_count)
        res$isopeak_count <- sum(z$isopeak_count)
        res$isopeak_sim <- mean(z$isopeak_sim)
        res$ms2_count <- sum(z$ms2_count)
        res$ms2_matched_count <- sum(z$ms2_matched_count)
        res$ms2_true_count <- sum(z$ms2_true_count)
        res
    }) |>
    do.call(what = rbind) |>
    as.data.frame()


## plots 
eic <- chromPeakChromatograms(x_mse_pos, 
                              peaks = x_match_res$chrom_peak_id[idx], 
                              expandRt = 10, 
                              expandMz =0.02)
fData(eic)$adduct <- x_match_res$adduct[idx]
plot(eic) ## i'd like t plot with the adduct as a subtitle but i'm struggling. 

## - i would then actually perform all the plots here below and organize them per standard/regions/... 
## It would mean some reorganisation, i want to check if that make sense first. 
```
  
- output should be: regions rt limit, number of adducts ?

- position of peak compared to NAPS peaks

- peak shape correlation score between peaks of same regions. 
This is were we test the peak shape correlation that Anna tested using
artificial data. We would need some other way to confirm this though, not sure
how..

